import tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256,6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256, 6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256,6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256, 6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256,6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256, 6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256,6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as neededmport tensorflow as tf

# Load the dataset (replace with your dataset path)
dataset_path = 'path/to/your/dataset'
train_dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_path)
from tensorflow.keras import layers, Model

def build_generator():
    inputs = layers.Input(shape=(256, 256, 3))
    
    # Downsampling
    down_stack = [
        layers.Conv2D(64, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2D(256, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    x = inputs
    for layer in down_stack:
        x = layer(x)
    
    # Upsampling
    up_stack = [
        layers.Conv2DTranspose(128, (4, 4), strides=2, padding='same', activation='relu'),
        layers.Conv2DTranspose(64, (4, 4), strides=2, padding='same', activation='relu'),
    ]
    
    for layer in up_stack:
        x = layer(x)
    
    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    def build_discriminator():
    inputs = layers.Input(shape=(256, 256, 6))  # Concatenated input and target image
    x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = layers.LeakyReLU(alpha=0.2)(x)
    
    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    return Model(inputs=inputs, outputs=outputs)
    generator = build_generator()
discriminator = build_discriminator()

generator.compile(optimizer='adam', loss='mae')  # Mean Absolute Error for generator
discriminator.compile(optimizer='adam', loss='binary_crossentropy')  # Binary Crossentropy for discriminator
import numpy as np

def train(dataset):
    for epoch in range(num_epochs):
        for image_batch in dataset:
            # Generate fake images from the generator
            fake_images = generator(image_batch[0])  # Assuming image_batch[0] is input
            
            # Train discriminator on real and fake images
            real_labels = np.ones((batch_size,) + discriminator.output_shape[1:])
            fake_labels = np.zeros((batch_size,) + discriminator.output_shape[1:])
            
            d_loss_real = discriminator.train_on_batch(np.concatenate([image_batch[0], image_batch[1]], axis=-1), real_labels)  # Real images
            d_loss_fake = discriminator.train_on_batch(np.concatenate([image_batch[0], fake_images], axis=-1), fake_labels)  # Fake images
            
            # Train generator via adversarial loss and L1 loss
            g_loss = generator.train_on_batch(image_batch[0], image_batch[1])  # Target images
            
            print(f'Epoch: {epoch}, D Loss Real: {d_loss_real}, D Loss Fake: {d_loss_fake}, G Loss: {g_loss}')
            # Generate new images from test data
test_images = ... # Load or define your test dataset here
generated_images = generator.predict(test_images)

# Save or display generated images as needed